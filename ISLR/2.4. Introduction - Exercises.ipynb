{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.\n",
    "\n",
    "(a) The sample size n is extremely large, and the number of predictors p is small.\n",
    "\n",
    "*Flexible better*\n",
    "\n",
    "(b) The number of predictors p is extremely large, and the number of observations n is small.\n",
    "\n",
    "*Inflexible better, flexible would overfit small number of observations.*\n",
    "\n",
    "(c) The relationship between the predictors and response is highly non-linear.\n",
    "\n",
    "*Flexible better, more degrees of freedom*\n",
    "\n",
    "(d) The variance of the error terms, i.e. σ2 = Var(ε), is extremely high.\n",
    "\n",
    "*Inflexible better. Flexible methods fit to the noise in the error terms and increase variance*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.\n",
    "\n",
    "(a) We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.\n",
    "\n",
    "Regression. Interested in inference. Quantitative output of CEO salary based on CEO firm's features  \n",
    "n = 500  \n",
    "p = profit, number of employees, industry\n",
    "\n",
    "\n",
    "(b) We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.\n",
    "\n",
    "Classification. Success or Failure classifier. Interested in prediction.  \n",
    "n = 20  \n",
    "p = price charged, marketing budget, competition price, 10 other variables  \n",
    "\n",
    "\n",
    "(c) We are interesting in predicting the % change in the US dollar in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the dollar, the % change in the US market, the % change in the British market, and the % change in the German market.\n",
    "\n",
    "Regression.  \n",
    "n = 52 (weeks)  \n",
    "p = % change in US market, British market, German market  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) We now revisit the bias-variance decomposition.\n",
    "(a) Provide a sketch of typical (squared) bias, variance, training er- ror, test error, and Bayes (or irreducible) error curves, on a sin- gle plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one.\n",
    "\n",
    "\n",
    "![title](input_figures/2-4 q3.jpg)\n",
    "\n",
    "i. (squared) bias - decreases monotonically because increases in flexibility\n",
    "yield a closer fit  \n",
    "\n",
    "ii. variance - increases monotonically because increases in flexibility yield\n",
    "overfit  \n",
    "\n",
    "iii. training error - decreases monotonically because increases in flexibility\n",
    "yield a closer fit  \n",
    "\n",
    "iv. test error - concave up curve because increase in flexibility yields a closer\n",
    "fit before it overfits  \n",
    "\n",
    "v. Bayes (irreducible) error - defines the lower limit, the test error is bounded \n",
    "below by the irreducible error due to variance in the error (epsilon) in the output \n",
    "values (0 <= value). When the training error is lower than the irreducible error,\n",
    "overfitting has taken place.  \n",
    "The Bayes error rate is defined for classification problems and is determined by \n",
    "the ratio of data points which lie at the 'wrong' side of the decision boundary, \n",
    "(0 <= value < 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) You will now think of some real-life applications for statistical learning.\n",
    "\n",
    "(a) Describe three real-life applications in which classification might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.  \n",
    "\n",
    "1. Classification of species. Inference.  \n",
    "2. Predicting weather. Prediction.  \n",
    "3. Loan applicability. Inference.  \n",
    "\n",
    "(b) Describe three real-life applications in which regression might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.\n",
    "\n",
    "1. Predicting house prices. Prediction.  \n",
    "2. MPG of a car. Inference.  \n",
    "3. Plant growth. Prediction.  \n",
    "\n",
    "(c) Describe three real-life applications in which cluster analysis might be useful.\n",
    "\n",
    "1. Disease - Drug sensitivity/resistance\n",
    "2. Assigning Heat/Electricity output to modes of a power plant\n",
    "3. Segmentation of customer base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?\n",
    "\n",
    "The disadvantages for a very flexible approach for regression or classification\n",
    "are requires estimating a greater number of parameters, follow the noise too\n",
    "closely (overfit), increasing variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
