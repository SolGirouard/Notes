{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Â Question 1\n",
    "\n",
    "Describe the null hypothesis to which the p-values given in Table 3.4 correspond. Explain what conclusions you can draw based on these p-values. Your explanation should be phrased in terms of `sales`, `TV`, `radio` and `newspaper`.\n",
    "\n",
    "Table 3.4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|           | Coefficient | Std. Error | t-statistic | p-value  |\n",
    "|-----------|-------------|------------|-------------|----------|\n",
    "| Intercept | 2.939       | 0.3119     | 9.42        | < 0.0001 |\n",
    "| TV        | 0.046       | 0.0014     | 32.81       | < 0.0001 |\n",
    "| Radio     | 0.189       | 0.0086     | 21.89       | < 0.0001 |\n",
    "| Newspaper | -0.01       | 0.0059     | -0.18       | 0.8599   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 - Answer\n",
    "\n",
    "The null hypothesis is that there is no effect on sales resulting from a change in spending on advertising in TV, radio or newspaper.\n",
    "\n",
    "The p-values for TV and Radio indicate that there is a significant effect on sales caused by an increase in advertising on TV and Radio, so we can reject this null hypothesis for these two media.\n",
    "\n",
    "However, the high p-value for Newspaper advertising indicates that we cannot reject the null hypothesis in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "\n",
    "Carefully explain the differences between th KNN classifier and the KNN regression methods.\n",
    "\n",
    "#### Question 2 Answer\n",
    "\n",
    "The KNN classifier and regression models are very similar and their formulae are very similar. \n",
    "\n",
    "The KNN regression method averages the K nearest training points in Euclidean space to x<sub>0</sub> and gives a quantitative output.\n",
    "\n",
    "The KNN classifier method gives a probability of x<sub>0</sub> belonging to a category (qualitative response) by taking the K nearest training points in Euclidean space and calculating how many belong to category j as a proportion of K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "\n",
    "Suppose we have a data set with five predictors:   \n",
    "$X_1 = GPA$  \n",
    "$X_2 = IQ$  \n",
    "$X_3 = \\text{Gender (1 for Female, 0 for Male)}$  \n",
    "$X_4 = \\text{Interaction between GPA and IQ}$  \n",
    "$X_5 = \\text{Interaction between GPA and Gender}$  \n",
    "\n",
    "The response is starting salary after graduation (in thousands of dollars).\n",
    "\n",
    "Suppose we use the least squares to fit the model and get:  \n",
    "$\\hat{\\beta_0} = 50$  \n",
    "$\\hat{\\beta_1} = 20$  \n",
    "$\\hat{\\beta_2} = 0.07$  \n",
    "$\\hat{\\beta_3} = 35$  \n",
    "$\\hat{\\beta_4} = 0.01$  \n",
    "$\\hat{\\beta_5} = -10$  \n",
    "\n",
    "a) Which answer is correct and why?:  \n",
    "i. For a fixed value of IQ and GPA, males earn more on average than females  \n",
    "ii. For a fixed value of IQ and GPA, females earn more on average than males  \n",
    "iii. For a fixed value of IQ and GPA, males earn more on average than females, provided the GPA is high enough.  \n",
    "iv. For a fixed value of IQ and GPA, females earn more on average than males provided that the GPA is high enough.  \n",
    "\n",
    "b) Predict the salary of a female with IQ of 110 and a GPA of 4\n",
    "\n",
    "c) True or False: Since the coefficient for the GPA/IQ interaction term is very small, there is very little evidence of an interaction effect. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 Answer\n",
    "\n",
    "$Y = 50 + 20(GPA) + 0.07(IQ) + 35(Gender) + 0.01(GPA * IQ) - 10(GPA * Gender)$\n",
    "\n",
    "a)  \n",
    "For Males (Gender = 0):  \n",
    "$Y = 50 + 20a + 0.07b + 0.01ab$  \n",
    "For Females (Gender = 1):  \n",
    "$Y = 85 + 20a + 0.07b + 0.01ab - 10a$\n",
    "\n",
    "Therefore iii is true. For a fixed value of IQ And GPA, males earn more on average than females, provided GPA is high enough\n",
    "\n",
    "b)  \n",
    "Y = 50 + (20 * 4) + (0.07 * 110) + (35 * 1) + (0.01 * 4 * 110) - (10 * 4 * 1)  \n",
    "Y = 137.1  \n",
    "Salary = $137100\n",
    "\n",
    "c)\n",
    "False. Without a p-value we cannot determine whether this term is statistically significant. A small coefficient with very large values can have a large effect and v.v."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "I collect a set of data (n=100 observations) containing a single predictor and a quantitative response.    \n",
    "I then fit a linear regression to the model to the data, as well as a separate cubic regression (i.e. $ Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\epsilon$)\n",
    "\n",
    "a) Suppose the true relationship between X and Y is linear. Consider the training residual sum of squares (RSS) for th linear and cubic regressions. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "\n",
    "b) Answer a) using a test rather than training RSS\n",
    "\n",
    "c) Suppose that the true relationship between X and Y is not linear, but we don't know how far it is from linear. Which RSS would we expect to be lower on the training set? Or would they be the same? Or is there not enough information to tell?\n",
    "\n",
    "d) Answer c) using a test rather than training RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 - Answers\n",
    "\n",
    "a) We would expect the cubic regression would perform better (lower RSS), as it is more flexible so can fit better to the training data.\n",
    "\n",
    "b) We would expect the linear regression to perform better (lower RSS) on the test set as the cubic regression would be overfit to the training data, where the real data is linear.\n",
    "\n",
    "c) Same as a), regardless of distribution.\n",
    "\n",
    "d) There is not enough information to tell, if it is very close to linear, the linear may perform better. If it is very far from linear, the cubic regression may perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "\n",
    "Consider the fitted values that result from performing linear regression without an intercept. In this setting the ith fitted value takes the form:\n",
    "\n",
    "$ \\hat{y_i} = x_i\\hat{\\beta}$\n",
    "\n",
    "Where:\n",
    "\n",
    "$ \\hat{\\beta} = \\dfrac{\\Sigma^n_{i=1} x_i y_i}{\\Sigma^n_{i'=1} x_{i'}^2}$\n",
    "\n",
    "Show that we can write:\n",
    "\n",
    "$ \\hat{y_i} = \\Sigma^n_{i'=1} a_{i'} y_{i'} $\n",
    "\n",
    "What is $ a_{i'}$?\n",
    "\n",
    "_Note: We interpret this result by saying tha tthe fitted values from linear regresion are the linear combinations of the response values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of simple linear regression, show that the least squares line always passes through the point $(\\bar{x}, \\bar{y})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6 Answer\n",
    "\n",
    "Starting with:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 x$  \n",
    "\n",
    "If a point (x, y) is on the line then:\n",
    "\n",
    "$ \\beta_0 + \\beta_1 x - y = 0 $\n",
    "\n",
    "So substituting in $(\\bar{x}, \\bar{y})$:\n",
    "\n",
    "$ \\beta_0 + \\beta_1\\bar{x} - \\bar{y} = 0 $\n",
    "\n",
    "We know that the minimiser for $\\beta_0$ is calculated as:\n",
    "\n",
    "$ \\beta_0 = \\bar{y} - \\beta_1\\bar{x} $\n",
    "\n",
    "So, substituting this in for $\\beta_0$, we get:\n",
    "\n",
    "$ \\bar{y} - \\beta_1\\bar{x} + \\beta_1\\bar{x} - \\bar{y} = 0 $\n",
    "\n",
    "Which simplifies to $ 0 = 0 $, so is true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7\n",
    "\n",
    "It is claimed in the text that in the case of simple linear regression of Y onto X, the R<sup>2</sup> statistic is equal to the square of the correlation between X and Y. Prove that this is the case. For simplicity, you may assume that $ \\bar{x} = \\bar{y} = 0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
