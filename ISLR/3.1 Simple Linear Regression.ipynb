{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Simple Linear Regression\n",
    "\n",
    "Simple linear regression lives up to its name: it is a very straightforward approach for predicting a quantitative response Y on the basis of a single predictor variable X.\n",
    "\n",
    "It assumes that there is an approximately linear relationship between X and Y. Mathematically, we can write this linear relationship as:\n",
    "\n",
    "$ Y \\approx \\beta_0 + \\beta_1X $\n",
    "\n",
    "For example, if we regress sales onto TV by fitting the model:\n",
    "\n",
    "$ sales \\approx \\beta_0 + \\beta_1 \\times TV $\n",
    "\n",
    "Once we have used our training data to produce estimates $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ for the model coefficients, we can predict future sales on the basis of a particular value of TV advertising by computing:\n",
    "\n",
    "$\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x$\n",
    "\n",
    "Where $\\hat{y}$ indicates a prediction of Y on the basis of X = x. Here we use a hat symbole to denote the estimated value for an unknown parameter or coefficient, or to denote the predicted value of the response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.1 Estimating the Coefficients\n",
    "\n",
    "In practice, $\\hat{\\beta_0}$ and $\\hat{\\beta_1}x$ are unknown. So before we can use the equations above to make predictions, we must use the data to estimate the coefficients. Let:\n",
    "\n",
    "$ (x_1, y_1), (x_2, y_2), ..., (x_n, y_n)$  \n",
    "\n",
    "represent n observation pairs, each of which consists of a measurement of X and a measurement of Y. In the `Advertising` example, this data set consists of the TV advertising budget and product sales in n = 200 different markets. \n",
    "\n",
    "Our goal is to obtain coefficient estimates $\\hat{\\beta_0}$ and $\\hat{\\beta_1}x$ such that the linear model fits the available data well - that is, so that $y_i \\approx \\hat{\\beta_0} + \\hat{\\beta_1}x_i$ for $i = 1, ..., n$\n",
    "\n",
    "In other words, we want to find an intercept $\\hat{\\beta_0}$ and a slope $\\hat{\\beta_1}$ such that the resulting line is as close as possible to the n = 200 data points.\n",
    "\n",
    "There are a number of ways of measuring _closeness_. However, by far the most common approach involves minimising the least squares criterion and we will take that approach in this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](input_figures/Fig 3-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Advertising data, the least squares fit for the regression of sales onto TV is shown\n",
    "\n",
    "If we let:  \n",
    "$ \\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1}x_i$  \n",
    "Then:  \n",
    "$ e_i = y_i - \\hat{y_i} $  \n",
    "represents the $i^th$ residual.  \n",
    "\n",
    "We define the residual sum of squares (RSS) as\n",
    "\n",
    "$RSS = e^2_1 + e^2_2 + ... + e^2_n $\n",
    "\n",
    "Or equivalently as:\n",
    "\n",
    "$ RSS = (y_1 - \\hat{\\beta_0} - \\hat{\\beta_1}x_1)^2 + (y_2 - \\hat{\\beta_0} - \\hat{\\beta_1}x_2)^2 ... + (y_n - \\hat{\\beta_0} - \\hat{\\beta_1}x_n)^2 $\n",
    "\n",
    "The least squares approach chooses \\hat{\\beta_0} and \\hat{\\beta_1} to minimize the RSS. Using some calculus, one can show that the minimisers are:\n",
    "\n",
    "$ \\hat{\\beta_1} = \\dfrac{\\Sigma^n_{i=1} (x_i - \\bar{x})(y_i - \\bar{y})}{\\Sigma^n_{i=1} (x_i - \\bar{x})^2} $  \n",
    "\n",
    "$ \\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x} $  \n",
    "\n",
    "The figure above displays the simple linear regression fit to the Advertising data, where:  \n",
    "$ \\hat{\\beta_0} = 7.03 $  \n",
    "$ \\hat{\\beta_1} = 0.0475 $  \n",
    "\n",
    "In other words, an additional $1000 spent on TV advertising is associated with selling approximately 47.5 additional units of this product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2. Assessing the Accuracy of the Coefficient Estimates\n",
    "\n",
    "If we assume that the true relationship between X and Y takes the form $Y = f(x) + \\epsilon$ for some unknown function f, where $\\epsilon$ is a mean-zero random error term.  \n",
    "  \n",
    "If f is to be approximated by a linear function then we can write this relationship as:\n",
    "\n",
    "$ Y = \\beta_0 + \\beta_1X + \\epsilon$\n",
    "\n",
    "Because we rarely know the actual relationship, we will only ever be estimating the values above as long as we have a sample of the population.\n",
    "\n",
    "To work out how how accurate the sample mean $\\hat{\\mu}$ as an estimate of ${\\mu}$ we will use the _standard error_ of $\\hat{\\mu}$, written as $SE(\\hat{\\mu})$. We have the well known formula:  \n",
    "\n",
    "$Var(\\hat{\\mu}) = SE(\\hat{\\mu})^2 = \\dfrac{\\sigma^2}{n}$\n",
    "\n",
    "where $\\sigma$ is the standard deviation of each of the realisations $y_i$ of Y.\n",
    "\n",
    "Roughly speaking, the standard error tells us the average amount that this estimate $\\hat{\\mu}$ differs from the actual value of $\\mu$\n",
    "\n",
    "In a similar vein, we can wonder how close $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ are to the true values $\\beta_0$ and $\\beta_1$. To compute the standard errors associated with $\\beta_0$ and $\\beta_1$ we use the following formulae:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ SE(\\hat{\\beta_0})^2 = \\sigma^2\\Big[\\dfrac{1}{n} + \\dfrac{\\bar{x}^2}{\\Sigma^n_{i=1}(x_i - \\bar{x})^2}\\Big] $  \n",
    "\n",
    "$ SE(\\hat{\\beta_1})^2 = \\dfrac{\\sigma^2}{\\Sigma^n_{i=1}(x_i - \\hat{x})^2} $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general $\\sigma^2$ is not known but it can be estimated from the data. The estimate of $\\sigma$ is known as the residual standard error, and is given by the formula:\n",
    "\n",
    "$ RSE = \\sqrt{RSS/(n-2)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Linear regression, the 95% confidence interval for $\\beta_1$ approximately takes the form:\n",
    "\n",
    "$ \\hat{\\beta_1} \\pm 2 \\cdot SE(\\hat{\\beta_1}) $\n",
    "\n",
    "That is, there is approximately a 95% chance that the interfal:\n",
    "\n",
    "$\\Big[ \\hat{\\beta_1} - 2 \\cdot SE(\\hat{\\beta_1}), \\hat{\\beta_1} + 2 \\cdot SE(\\hat{\\beta_1})\\Big] $\n",
    "\n",
    "will contain the true value of $\\beta_1$\n",
    "\n",
    "This is true of $\\hat{\\beta_0}$ also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of advertising data, the 95% confidence interval for $\\hat{\\beta_0}$ is [6.130, 7.935] and the 95% confidence interval for $\\hat{\\beta_1}$ is [0.042, 0.053]. Therefore we can conclude that in the absence of any advertising, sales wil, on average, fall somewhere between 6,130 and 7,940 units. We can also conclude that for each \\$1000 increase in television advertising, there will be an average increase in sales between 42 and 53 units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Standard Errors to perform hypothesis tests\n",
    "\n",
    "The most common hypothesis test involves testing the null hypothesis of:\n",
    "\n",
    "$H_0$: There is no relationship between X and Y  \n",
    "\n",
    "versus the alternative hypothesis\n",
    "\n",
    "$H_a$: Thre is some relationship between X and Y.\n",
    "\n",
    "Mathematically, this corresponds to testing:\n",
    "\n",
    "$H_0: \\beta_1 = 0 $  \n",
    "$H_a: \\beta_1 \\neq 0 $  \n",
    "\n",
    "We need to consider both the scale and accuracy of $\\beta_1$, a small $\\beta_1$ may still be significant.\n",
    "\n",
    "In practice we compute a t-statistic, given by:\n",
    "\n",
    "$ t = \\dfrac{\\hat{\\beta_1} - 0}{SE(\\beta_1)}$\n",
    "\n",
    "Which measues the number of standard deviations that $\\beta_1$ is from zero.\n",
    "\n",
    "The t distribution is similar to the normal distribution and it is a simple matter to compute the probability of observing any value equal to |t| or larger, assuming $\\beta_1 = 0$. We call this probability the p-value.\n",
    "\n",
    "A small p value indicates it is unlikely to observe such a substantial association between the predictor and the response due to chance. Therefore we can infer that there is an association between the predictor and the response.\n",
    "\n",
    "When n = 30, a p-value of 5% or 1% corresponds to t-statistics of around 2 and 2.75 respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the Accuracy of the Model\n",
    "\n",
    "Once we have rejected the null hypothesis in favour of the alternative hypothesis, it is natural to want to quantify the extent to which the model fits the data.\n",
    "\n",
    "The quality of a linear regression fit is typically assessed using two related quantities: the residual standard eror (RSE) and the $R^2$ statistic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
